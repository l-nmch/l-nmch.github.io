---
date: '2025-06-29T19:26:04+02:00'
title: 'Un setup IA moins cher que Mario Kart World ?'
description: "Comment faire un setup IA pour une bouch√©e de pain, et est-ce que c'est vraiment int√©ressant ?"
tags: ["GenAI", "Z440", "NVIDIA", "AI", "GPU", "Inference", "LLM", "Tensorflow", "Docker"]
---

# Un setup IA moins cher que Mario Kart World ?

---

## üî¥ Pourquoi faire de l'IA chez soi ?

C'est vrai √ßa, pourquoi faire de l'IA chez soi ? Et puis d'abord, c'est quoi l'IA ?

### Qu'est-ce que l'IA ?

Selon [Wikipedia](https://fr.wikipedia.org/wiki/Intelligence_artificielle) :

> L'intelligence artificielle (IA) est la capacit√© des machines √† effectuer des t√¢ches typiquement associ√©es √† l'intelligence humaine, comme l'apprentissage, le raisonnement, la r√©solution de probl√®me, la perception ou la prise de d√©cision. L'intelligence artificielle est √©galement le champ de recherche visant √† d√©velopper de telles machines ainsi que les syst√®mes informatiques qui en r√©sultent.

En somme, l‚ÄôIA, c‚Äôest utiliser des fonctions et des op√©rations math√©matiques pour automatiser et acc√©l√©rer des t√¢ches complexes, en reproduisant des comportements humains comme la lecture, la vision, l‚Äô√©criture ou encore la compr√©hension du langage. Gr√¢ce √† ces calculs, les machines peuvent apprendre √† reconna√Ætre des images, comprendre du texte, prendre des d√©cisions ou m√™me cr√©er du contenu, souvent plus vite et parfois mieux que nous (en vrai c'est discutable).

### Mais pourquoi faire de l'IA chez soi ?

D√©j√†, j‚Äôaime avoir le contr√¥le total de ce que je fais et des outils que j‚Äôutilise. Pas par parano√Øa, mais parce que j‚Äôaime comprendre les choses √† ma fa√ßon ‚Äî et pas selon celle d‚Äôun cloud provider, d‚Äôun SaaS ou de toute autre entit√©. √áa me permet d‚Äôapprendre ce qu‚Äôest l‚ÄôIA, de comprendre la partie hardware et software, et de rencontrer des probl√®mes qu‚Äôon ne voit pas forc√©ment ailleurs.

Mais il y a aussi plusieurs cas d‚Äôusage bien plus concrets :

- **Souverainet√© des donn√©es** : garder le contr√¥le total de ses donn√©es sensibles.
- **√âconomie financi√®re** : √©viter les co√ªts √©lev√©s des services cloud, surtout sur le long terme.
- **Personnalisation des mod√®les** : entra√Æner ou affiner des mod√®les sp√©cifiquement adapt√©s √† ses besoins m√©tier.
- **Confidentialit√© et s√©curit√©** : r√©duire les risques de fuite ou vol de donn√©es.
- **Disponibilit√© et latence** : avoir un acc√®s rapide √† ses services d‚ÄôIA, m√™me sans internet.

---

## üîß Mon setup

### Le hardware

Mon setup est bas√© sur un [HP Z440](https://support.hp.com/be-fr/product/details/hp-z440-workstation/6978828) et contient :

- Alimentation HP 700W  
- [Intel Xeon E5-1620 v3 @ 3.50GHz](https://www.intel.fr/content/www/fr/fr/products/sku/82763/intel-xeon-processor-e51620-v3-10m-cache-3-50-ghz/specifications.html)  
- 32 Go RAM DDR4 ECC 2133MHz  
- [SSD Samsung EVO 250 Go](https://www.samsung.com/fr/memory-storage/sata-ssd/870-evo-250gb-sata-3-2-5-ssd-mz-77e250b-eu/)  
- [Quadro K2200 4 Go](https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/documents/75509_DS_NV_Quadro_K2200_US_NV_HR.pdf)  
- [GTX 1050 Ti 4 Go](https://www.gigabyte.com/fr/Graphics-Card/GV-N105TG1-GAMING-4GD)  
- [GT 1030 2 Go](https://www.gigabyte.com/fr/Graphics-Card/GV-N1030D5-2GL)

J'ai eu le **Z440** avec **CPU**, **alim** et **Quadro K2200** pour *45 ‚Ç¨*.  
La RAM a √©t√© achet√©e sur [Ebay](https://ebay.fr) pour *30 ‚Ç¨*.

Le reste, c‚Äôest de la r√©cup !

**Co√ªt total : 75 ‚Ç¨**

Co√ªt annonc√© par Nintendo pour [Mario Kart World](https://www.nintendo.com/fr-fr/Jeux/Jeux-Nintendo-Switch-2/Mario-Kart-World-2790000.html) : *79,99 ‚Ç¨*

> P.S. Je m'√©tais d√©got√© une belle [AMD Radeon Instinct Mi50 16 Go](https://www.techpowerup.com/gpu-specs/radeon-instinct-mi50.c3335) pour **129 ‚Ç¨** mais elle a d√©cid√© de rendre l'√¢me... Je n‚Äôai malheureusement pas pu d√©terminer pourquoi.

![HP Z440](https://ssl-product-images.www8-hp.com/digmedialib/prodimg/lowres/c05263682.png)

### Le software

Pour l'OS, mon choix s‚Äôest port√© sur [Ubuntu Server 24.04](https://ubuntu.com/).  
Pourquoi ? Parce qu'**Ubuntu** facilite √©norm√©ment l'installation des drivers [NVIDIA](https://www.nvidia.com/fr-fr/) et b√©n√©ficie d‚Äôun meilleur support pour l‚ÄôIA et le compute que d‚Äôautres distros comme [Debian](https://www.debian.org/).

C√¥t√© apps et langages :

- [Ollama](https://ollama.com) : pour l'utilisation de LLMs
- [NVtop](https://github.com/Syllo/nvtop) : pour monitorer l'utilisation GPU fa√ßon [htop](https://htop.dev/)
- [Docker](https://docker.com) : pour containeriser mes apps et services

---

## ‚öôÔ∏è Mise en place des pr√©requis

C‚Äôest la partie un peu reloue. Mettre en place tous les pr√©requis pour les applis cit√©es ci-dessus prend du temps, de la doc, et pas mal de patience.

### Installation des drivers NVIDIA & NVtop

D'abord, on liste les drivers disponibles :

```bash
sudo ubuntu-drivers devices
```

```
== /sys/devices/pci0000:00/0000:00:02.0/0000:02:00.0 ==
modalias : pci:v000010DEd000013BAsv0000103Csd00001097bc03sc00i00
vendor   : NVIDIA Corporation
model    : GM107GL [Quadro K2200]
driver   : nvidia-driver-470 - distro non-free
driver   : nvidia-driver-535-server - distro non-free
driver   : nvidia-driver-550 - distro non-free
driver   : nvidia-driver-570-server - distro non-free
driver   : nvidia-driver-570 - distro non-free recommended # <=====
driver   : nvidia-driver-470-server - distro non-free
driver   : nvidia-driver-535 - distro non-free
driver   : xserver-xorg-video-nouveau - distro free builtin
```

> P.S. On ne voit ici qu'une seule carte, c‚Äôest normal, c‚Äôest celle avec les d√©pendances les plus anciennes.

Ensuite:

```bash
sudo ubuntu-drivers autoinstall
```

Et voil√†, avec **Ubuntu**, c‚Äôest presque trop simple.

Maintenant pour **NVtop** :

```bash
sudo apt install -y nvtop
```

On v√©rifie tout : 

```bash
nvidia-smi # System Management Interface(Nous permet d'obtenir des infos plus d√©taill√©s sur nos cartes graphiques)
```

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce GT 1030         Off |   00000000:01:00.0 Off |                  N/A |
|  0%   33C    P8            N/A  /   30W |       4MiB /   2048MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Quadro K2200                   Off |   00000000:02:00.0  On |                  N/A |
| 42%   31C    P8              1W /   39W |      10MiB /   4096MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce GTX 1050 Ti     Off |   00000000:03:00.0 Off |                  N/A |
|  0%   25C    P8            N/A  /  120W |       5MiB /   4096MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

OK ! Toutes nos cartes sont l√†, maintenant on test **NVtop**

```bash
nvtop
```

![Output NVtop](/img/nvtop.png)

Magnifique !

### Installation de Docker & Nvidia Container Toolkit

[Nvidia Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-the-nvidia-container-toolkit) ? C'est quoi encore cette m*rde ?

C'est ce qui vas nous permettre d'utiliser nos cartes graphiques(GPU) dans des containers **Docker**.

Avant de passer √† cette √©tape il faut installer **Docker** :

```bash
curl https://get.docker.com | sh
```

> P.S. Cette m√©thode d'installation est rapide, mais √† √©viter en prod ! En cas de compromission de `get.docker.com`, un malware ou autre peut vite prendre le controle de votre machine.

Et maintenant, **Nvidia Container Toolkit** :

```bash
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

Cette commande ajoute les repositories officiel pour le **Nvidia Container Toolkit** et les cl√©es [GPG](https://fr.wikipedia.org/wiki/GNU_Privacy_Guard) n√©c√©ssaire.

On met √† jour nos sources :

```bash
sudo apt update
```

On installe les paquets n√©c√©ssaires :

```bash
export NVIDIA_CONTAINER_TOOLKIT_VERSION=1.17.8-1 # Bien penser √† mettre la derni√®re version pour avoir toutes les M√ÄJ et patches !
  sudo apt-get install -y \
      nvidia-container-toolkit=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
      nvidia-container-toolkit-base=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
      libnvidia-container-tools=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
      libnvidia-container1=${NVIDIA_CONTAINER_TOOLKIT_VERSION}
```

Maintenant, place √† la partie technique :

```bash
sudo nvidia-ctk runtime configure --runtime=docker
```

Cette commande va mettre √† jour le fichier `/etc/docker/daemon.json` pour dire √† **Docker** d'utiliser le [runtime](https://fr.wikipedia.org/wiki/Environnement_d%27ex%C3%A9cution) **Nvidia Container Toolkit** afin de pouvoir communiquer avec les GPU de fa√ßon plus s√©curis√©e, plus stable et plus norm√©e que de monter le ou les GPU en tant que device dans des containers.

Et ensuite, on red√©marre **Docker** pour que les changements prennent effet :

```bash
sudo systemctl restart docker
```

Petit test :

```bash
sudo docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce GT 1030         Off |   00000000:01:00.0 Off |                  N/A |
|  0%   36C    P8            N/A  /   30W |       4MiB /   2048MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Quadro K2200                   Off |   00000000:02:00.0  On |                  N/A |
| 42%   32C    P8              1W /   39W |      10MiB /   4096MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce GTX 1050 Ti     Off |   00000000:03:00.0 Off |                  N/A |
|  0%   27C    P8            N/A  /  120W |       5MiB /   4096MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

Et BAM ! Tous nos GPU sont vus et utilisables par nos containers !

> P.S. c'est gra√ße √† l'option `--gpus all` que tous les GPU sont vus par le container.

## üñ±Ô∏è Maintenant on s'amuse :

Tous les pr√©-requis sont install√©s, on peut enfin s'amuser !

### Ollama et mod√®le de langage :

Pour commencer, on va utiliser **Ollama** un super outil qui nous permet d'installer et d'utiliser des [mod√®le de langage](https://fr.wikipedia.org/wiki/Mod%C3%A8le_de_langage) comme :

- [Deepseek](https://www.deepseek.com/)
- [Gemma](https://deepmind.google/models/gemma/)
- [Mistral](https://mistral.ai/fr)

Ici, pas de container(m√™me si c'est possible), on ne s'emb√™te pas :

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Et on est par√© :

```bash
ollama run gemma3:1b
```

On choisi un petit prompt comme `You are a history teacher and you are going to teach me something about the city of New York`.

Et on regarde l'usage de nos GPU via **NVtop** :

![NVtop GIF](/img/nvtop-ollama.gif)

Parfait ! On arrive √† lancer des **mod√®les de langage** sur nos GPU (ici seulement 1 due √† la taille du mod√®le qui est d'environ 800Mo)

### Tensorflow et entrainement :

Utiliser des mod√®les c'est bien, mais en coder soit m√™me, c'est encore mieux !

L√†, √ßa va √™tre tr√®s technique, je vous pr√©viens. On va parler de :

- [Tensorflow](https://tensorflow.org) : librairie Python pour l'IA et l'apprentissage automatique.
- **Dataset** : jeu de donn√©es sur lequel on se base pour entrainer notre model.
- [Jupyter Notebook](https://jupyter.org/) : environnement Web interactif pour d√©velopper et visualiser notre mod√®le.
- [Deep Convolutional Generative Adversarial Network(DCGAN)](https://www.tensorflow.org/tutorials/generative/dcgan) : faire se battre 2 mod√®les de machine learning utilisant des [convolution](https://fr.wikipedia.org/wiki/Convolution), un pour cr√©er des images, l'autre pour influencer le premier √† faire des images plus r√©alistes.

Bon en r√©alit√©, ici, je ne vais rien coder. Je vais utiliser le code propos√© par **Tensorflow** pour voir s'il est possible d'entrainer un mod√®le sur mon serveur.

> P.S. L'entrainement et l'inf√©rence d'un mod√®le d'IA n'ont rien √† voir au niveau de l'utilisation des ressources. En g√©n√©ral, entrainer un mod√®le consomme plus de ressources que d'inf√©rer sur un mod√®le.

D'abord, un peu de magie. Au lieu d'appliquer des configurations r√©seaux compliqu√©es, on va ouvrir un tunnel SSH :

```bash
ssh -L 8888:0.0.0.0:8888 user@gpu-server
```

Pourquoi ? Parce que par d√©faut, un serveur **Jupyter** n'√©coute qu'en localhost(127.0.0.1).

Ensuite, lan√ßons notre container **Docker** :

```bash
sudo docker run --gpus all -it --rm -p 8888:8888 quay.io/jupyter/tensorflow-notebook:cuda-ubuntu-24.04
```

Et c'est partie pour le fun !

On se connecte √† notre notebook via l'URL donn√©e par **Jupyter** et tadaa !

![Jupyter Notebook](/img/jupyternb.png)

Et on importe le notebook [**DCGAN**](https://www.tensorflow.org/tutorials/generative/dcgan) de chez **Tensorflow** √† la racine du dossier.

Maintenant on lance et on attend.

#### Que fait le notebook ?

Pour simplifier, le notebook va, dans l'ordre :

- Importer les libs n√©cessaires
- Charger le **Dataset** [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST) (60k image de chiffre de 0 √† 9 √©crits √† la main)
- Cr√©er le mod√®le `g√©n√©rateur` qui s'occupe de cr√©er des images de nombres en partant de bruit (une image greyscale avec des pixels al√©atoires)
- Cr√©er le mod√®le `discriminant` qui lui vas dire au `g√©n√©rateur` si l'image est *vrai* ou *fausse* en se basant sur le **Dataset** pour qu'il puisse g√©n√©rer d'autres images plus r√©alistes
- D√©finir la boucle d'entrainement, qui vas g√©n√©rer 16 images sur 50 it√©rations (EPOCHS), et sauvegarder un `checkpoint`(un √©tat des poids du mod√®le g√©n√©ral dans le temps) toutes les 15 it√©rations.
- Et nous cr√©er un magnifique GIF √† la fin pour nous montrer l'√©volution de la g√©n√©ration des images pour chaque it√©ration.

Apr√®s *30.501 secondes* voici notre 1√®re g√©n√©ration :

![Jupyter EPOCH1](/img/jupyter-epoch1.png)

C'est flou, on comprend rien, c'est normal ! c'est la premi√®re g√©n√©ration, l'entrainement ne fait que commencer.

En attendant la fin de l'entrainement, regardons ce qu'il se passe c√¥t√© utilisation de ressources :

![Jupyter NVtop](/img/jupyter-nvtop.png)

WOW ! VRAM pleine √† craqu√©, utilisation du GPU √† quasi 100% Mais pourquoi 1 seul GPU ? J'en ai 3 !

C'est tr√®s simple. Entrainer un mod√®le sur plusieurs GPU, c'est possible, mais pas sans configuration suppl√©mentaire.

Le notebook utilis√© n'est pas cod√© pour run sur plusieurs GPU. Mais cela viendra dans un prochain article, je vous rassure.

Ah !, c'est cuit ! Le mod√®le a fini son entrainement.

![GIF DCGAN](/img/dcgan.gif)

Bon... c'est moche, mais √ßa a march√© ! On distingue assez clairement des chiffres :

```
4 | 3 | 2 | ?
9 | 8 | ? | 9
? | 6 | 9 | ?
? | ? | 7 | 9
```

Sur 16 chiffres, seuls 4 ne sont vraiment pas lisibles, mais on a prouv√© qu'on peut entrainer un mod√®le !

## üîö Conclusion

Apr√®s tout ce chemin, qu'est-ce qu'on a appris ?

Pour moins de 80‚Ç¨, on a pu faire installer plusieurs outils li√©s √† l'IA, on a entrain√© un mod√®le d'IA g√©n√©ratrice d'image, on a utilis√© un LLM pour lui poser des questions, mais est-ce que √ßa en valait la peine ?

Bah √† mon sens... Carr√©ment !

Alors, OK, au niveau de la consommation de courant, on va vite finir dans le rouge et les GPU utilis√©s ne sont vraiment pas optimales pour devenir le prochain [OpenAI](https://openai.com).

Mais j'ai appris √©norm√©ment de choses :

- Mettre en place un environnement de d√©veloppement contain√©ris√© pour entrainer un mod√®le de g√©n√©ration d'image
- Mis les pieds dans le monitoring d'utilisation GPU
- Utiliser un LLM en local
- M√™me si on ne l'a pas vu ici, mais que ce n'est pas parce que j'ai 3 GPU que je peux magiquement faire plus de choses

Et tout √ßa pour moins cher que Mario Kart World !

> P.S. Il se peut que je fasse un second article avec des pr√©cisions, d'autres tests, et peut-√™tre m√™me du cloud-gaming